{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 6: Putting it all together \n",
    "### Associated lectures: All material till lecture 13 \n",
    "\n",
    "**Due date: Wednesday, March 15, 2023 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [Submission instructions](#si)\n",
    "- [Understanding the problem](#1)\n",
    "- [Data splitting](#2)\n",
    "- [EDA](#3)\n",
    "- (Optional) [Feature engineering](#4)\n",
    "- [Preprocessing and transformations](#5)\n",
    "- [Baseline model](#6)\n",
    "- [Linear models](#7)\n",
    "- [Different classifiers](#8)\n",
    "- (Optional) [Feature selection](#9)\n",
    "- [Hyperparameter optimization](#10)\n",
    "- [Interpretation and feature importances](#11)\n",
    "- [Results on the test set](#12)\n",
    "- (Optional) [Explaining predictions](#13)\n",
    "- [Summary of the results](#14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    plot_confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pandas_profiling as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022W2/blob/main/docs/homework_instructions.md). \n",
    "\n",
    "**You may work on this homework in a group and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 3. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "<hr>\n",
    "\n",
    "At this point we are at the end of supervised machine learning part of the course. So in this homework, you will be working on an open-ended mini-project, where you will put all the different things you have learned so far together to solve an interesting problem.\n",
    "\n",
    "A few notes and tips when you work on this mini-project: \n",
    "\n",
    "#### Tips\n",
    "\n",
    "1. This mini-project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). **Make sure you explain your decisions whenever necessary.** \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "4. If you are having trouble running models on your laptop because of the size of the dataset, you can create your train/test split in such a way that you have less data in the train split. If you end up doing this, please write a note to the grader in the submission explaining why you are doing it.  \n",
    "\n",
    "#### Assessment\n",
    "\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "#### A final note\n",
    "\n",
    "Finally, this style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\" (2-8 hours???) is a good guideline for a typical submission. Of course if you're having fun you're welcome to spend as much time as you want! But, if so, try not to do it out of perfectionism or getting the best possible grade. Do it because you're learning and enjoying it. Students from the past cohorts have found such kind of labs useful and fun and I hope you enjoy it as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the problem <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={points:4}\n",
    "\n",
    "In this mini project, you will be working on a classification problem of predicting whether a customer will cancel the reservation they have made at a hotel. \n",
    "For this problem, you will use [Reservation Cancellation Prediction Dataset](https://www.kaggle.com/datasets/gauravduttakiit/reservation-cancellation-prediction?select=train__dataset.csv). In this data set, there are about 18.000 examples and 18 features (including the target), and the goal is to estimate whether a person will cancel their booking; this column is labeled \"booking_status\" in the data (1 = canceled). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Spend some time understanding the problem and what each feature means. You can find this information in the documentation on [the dataset page on Kaggle](https://www.kaggle.com/datasets/gauravduttakiit/reservation-cancellation-prediction?select=train__dataset.csv). Write a few sentences on your initial thoughts on the problem and the dataset. \n",
    "2. Download the dataset and read it as a pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the features, the data types all seem to be numbers but not all are numerical features. I'm seeing some potential categorical or binary features which I'll expand on in another part. I'm not sure how relevant the market_segment_type feature will be, but the features that record the number of previous cancellations and non-cancellations feel like they might be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18132</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18133</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18134</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18135</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18136</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18137 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "0                 2               0                     1                  4   \n",
       "1                 2               1                     0                  2   \n",
       "2                 1               0                     1                  5   \n",
       "3                 1               0                     2                  4   \n",
       "4                 2               0                     0                  4   \n",
       "...             ...             ...                   ...                ...   \n",
       "18132             1               0                     0                  2   \n",
       "18133             2               0                     0                  3   \n",
       "18134             2               0                     0                  1   \n",
       "18135             2               0                     0                  3   \n",
       "18136             1               0                     1                  1   \n",
       "\n",
       "       type_of_meal_plan  required_car_parking_space  room_type_reserved  \\\n",
       "0                      0                           0                   0   \n",
       "1                      0                           0                   0   \n",
       "2                      0                           0                   0   \n",
       "3                      0                           0                   0   \n",
       "4                      1                           0                   0   \n",
       "...                  ...                         ...                 ...   \n",
       "18132                  0                           0                   0   \n",
       "18133                  0                           0                   0   \n",
       "18134                  0                           0                   0   \n",
       "18135                  0                           0                   0   \n",
       "18136                  0                           0                   0   \n",
       "\n",
       "       lead_time  arrival_year  arrival_month  arrival_date  \\\n",
       "0            118          2017             12            28   \n",
       "1             17          2018              4            14   \n",
       "2            349          2018             10             4   \n",
       "3             69          2018              6            12   \n",
       "4             11          2018              1            20   \n",
       "...          ...           ...            ...           ...   \n",
       "18132        103          2018              4            19   \n",
       "18133        129          2018              8            10   \n",
       "18134         90          2018              7            13   \n",
       "18135         18          2018             11            10   \n",
       "18136        159          2018              4             9   \n",
       "\n",
       "       market_segment_type  repeated_guest  no_of_previous_cancellations  \\\n",
       "0                        1               0                             0   \n",
       "1                        1               0                             0   \n",
       "2                        0               0                             0   \n",
       "3                        0               0                             0   \n",
       "4                        1               0                             0   \n",
       "...                    ...             ...                           ...   \n",
       "18132                    0               0                             0   \n",
       "18133                    1               0                             0   \n",
       "18134                    1               0                             0   \n",
       "18135                    1               1                             0   \n",
       "18136                    0               0                             0   \n",
       "\n",
       "       no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
       "0                                         0              110.80   \n",
       "1                                         0              145.00   \n",
       "2                                         0               96.67   \n",
       "3                                         0              120.00   \n",
       "4                                         0               69.50   \n",
       "...                                     ...                 ...   \n",
       "18132                                     0              115.00   \n",
       "18133                                     0               88.01   \n",
       "18134                                     0              105.30   \n",
       "18135                                     1              123.33   \n",
       "18136                                     0               65.00   \n",
       "\n",
       "       no_of_special_requests  booking_status  \n",
       "0                           2               0  \n",
       "1                           0               1  \n",
       "2                           0               1  \n",
       "3                           0               1  \n",
       "4                           1               0  \n",
       "...                       ...             ...  \n",
       "18132                       0               1  \n",
       "18133                       1               0  \n",
       "18134                       0               1  \n",
       "18135                       1               0  \n",
       "18136                       0               0  \n",
       "\n",
       "[18137 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train__dataset.csv\", encoding=\"utf-8\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data splitting <a name=\"2\"></a>\n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train and test portions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "X_train = train_df.drop(columns=[\"booking_status\"])\n",
    "X_test = test_df.drop(columns=[\"booking_status\"])\n",
    "\n",
    "y_train = train_df[\"booking_status\"]\n",
    "y_test = test_df[\"booking_status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA <a name=\"3\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. \n",
    "4. Pick appropriate metric/metrics for assessment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12695 entries, 15946 to 15725\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   no_of_adults                          12695 non-null  int64  \n",
      " 1   no_of_children                        12695 non-null  int64  \n",
      " 2   no_of_weekend_nights                  12695 non-null  int64  \n",
      " 3   no_of_week_nights                     12695 non-null  int64  \n",
      " 4   type_of_meal_plan                     12695 non-null  int64  \n",
      " 5   required_car_parking_space            12695 non-null  int64  \n",
      " 6   room_type_reserved                    12695 non-null  int64  \n",
      " 7   lead_time                             12695 non-null  int64  \n",
      " 8   arrival_year                          12695 non-null  int64  \n",
      " 9   arrival_month                         12695 non-null  int64  \n",
      " 10  arrival_date                          12695 non-null  int64  \n",
      " 11  market_segment_type                   12695 non-null  int64  \n",
      " 12  repeated_guest                        12695 non-null  int64  \n",
      " 13  no_of_previous_cancellations          12695 non-null  int64  \n",
      " 14  no_of_previous_bookings_not_canceled  12695 non-null  int64  \n",
      " 15  avg_price_per_room                    12695 non-null  float64\n",
      " 16  no_of_special_requests                12695 non-null  int64  \n",
      " 17  booking_status                        12695 non-null  int64  \n",
      "dtypes: float64(1), int64(17)\n",
      "memory usage: 1.8 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.0000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "      <td>12695.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.851359</td>\n",
       "      <td>0.106892</td>\n",
       "      <td>0.809137</td>\n",
       "      <td>2.202915</td>\n",
       "      <td>0.317290</td>\n",
       "      <td>0.032690</td>\n",
       "      <td>0.338007</td>\n",
       "      <td>85.579913</td>\n",
       "      <td>2017.820402</td>\n",
       "      <td>7.431587</td>\n",
       "      <td>15.743127</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>0.158724</td>\n",
       "      <td>103.519186</td>\n",
       "      <td>0.625286</td>\n",
       "      <td>0.326113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.515134</td>\n",
       "      <td>0.398709</td>\n",
       "      <td>0.870111</td>\n",
       "      <td>1.419864</td>\n",
       "      <td>0.630232</td>\n",
       "      <td>0.177831</td>\n",
       "      <td>0.775014</td>\n",
       "      <td>87.294409</td>\n",
       "      <td>0.383868</td>\n",
       "      <td>3.084243</td>\n",
       "      <td>8.765916</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.156759</td>\n",
       "      <td>0.355431</td>\n",
       "      <td>1.788642</td>\n",
       "      <td>35.370949</td>\n",
       "      <td>0.790905</td>\n",
       "      <td>0.468808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>375.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "count  12695.000000    12695.000000          12695.000000       12695.000000   \n",
       "mean       1.851359        0.106892              0.809137           2.202915   \n",
       "std        0.515134        0.398709              0.870111           1.419864   \n",
       "min        0.000000        0.000000              0.000000           0.000000   \n",
       "25%        2.000000        0.000000              0.000000           1.000000   \n",
       "50%        2.000000        0.000000              1.000000           2.000000   \n",
       "75%        2.000000        0.000000              2.000000           3.000000   \n",
       "max        4.000000        3.000000              7.000000          17.000000   \n",
       "\n",
       "       type_of_meal_plan  required_car_parking_space  room_type_reserved  \\\n",
       "count       12695.000000                12695.000000        12695.000000   \n",
       "mean            0.317290                    0.032690            0.338007   \n",
       "std             0.630232                    0.177831            0.775014   \n",
       "min             0.000000                    0.000000            0.000000   \n",
       "25%             0.000000                    0.000000            0.000000   \n",
       "50%             0.000000                    0.000000            0.000000   \n",
       "75%             0.000000                    0.000000            0.000000   \n",
       "max             3.000000                    1.000000            6.000000   \n",
       "\n",
       "          lead_time  arrival_year  arrival_month  arrival_date  \\\n",
       "count  12695.000000  12695.000000   12695.000000  12695.000000   \n",
       "mean      85.579913   2017.820402       7.431587     15.743127   \n",
       "std       87.294409      0.383868       3.084243      8.765916   \n",
       "min        0.000000   2017.000000       1.000000      1.000000   \n",
       "25%       16.000000   2018.000000       5.000000      8.000000   \n",
       "50%       57.000000   2018.000000       8.000000     16.000000   \n",
       "75%      127.000000   2018.000000      10.000000     23.000000   \n",
       "max      443.000000   2018.000000      12.000000     31.000000   \n",
       "\n",
       "       market_segment_type  repeated_guest  no_of_previous_cancellations  \\\n",
       "count           12695.0000    12695.000000                  12695.000000   \n",
       "mean                0.8000        0.025207                      0.022371   \n",
       "std                 0.6444        0.156759                      0.355431   \n",
       "min                 0.0000        0.000000                      0.000000   \n",
       "25%                 0.0000        0.000000                      0.000000   \n",
       "50%                 1.0000        0.000000                      0.000000   \n",
       "75%                 1.0000        0.000000                      0.000000   \n",
       "max                 4.0000        1.000000                     13.000000   \n",
       "\n",
       "       no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
       "count                          12695.000000        12695.000000   \n",
       "mean                               0.158724          103.519186   \n",
       "std                                1.788642           35.370949   \n",
       "min                                0.000000            0.000000   \n",
       "25%                                0.000000           80.100000   \n",
       "50%                                0.000000           99.450000   \n",
       "75%                                0.000000          120.600000   \n",
       "max                               58.000000          375.500000   \n",
       "\n",
       "       no_of_special_requests  booking_status  \n",
       "count            12695.000000    12695.000000  \n",
       "mean                 0.625286        0.326113  \n",
       "std                  0.790905        0.468808  \n",
       "min                  0.000000        0.000000  \n",
       "25%                  0.000000        0.000000  \n",
       "50%                  0.000000        0.000000  \n",
       "75%                  1.000000        1.000000  \n",
       "max                  5.000000        1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.info())\n",
    "display(train_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see in the first statistic that we don't have missing values and that the data types are all integers or floats. In the second statistic that I'll require standard scaling to the numeric features. Also, some of the features like repeated_guest and required_car_parking_space might be binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pr = pp.ProfileReport(train_df)\n",
    "pr.to_file(\"profilereport.html\") #exporting as html to save space when submitting this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHFCAYAAAAT5Oa6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPpklEQVR4nO3deViU5f4/8PewDfvI4rCJgAscTdTEQqwUxV1EbXM7pGVqrpGahuURrcTluH2z1KMmuYWnk1ipobihBhhSpKaZenAHIYVhEQeE+/eHP57jCMji4Iw+79d1zVVzP5+5537mnmHePtsohBACRERERDJmYugBEBERERkaAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DkUzExMRAoVDg+PHjVS4PDQ2Ft7e3Tpu3tzdGjRpVp+dJSkpCVFQU8vLy6jdQGdq2bRueeeYZWFlZQaFQID09vcq6muawIUVFRUGhUOCvv/56aN2oUaMqvY+o9irm+OLFi1Lbo7ymW7duxfLly6tcplAoEBUVVa9+G1pwcDDatGnT4M9Tn79x+hIcHIzg4OAa6+bPn48dO3ZUaj906BAUCgUOHTqk97HJFQMRVSsuLg6zZ8+u02OSkpIwd+5cBqJaysnJQXh4OJo3b474+HgkJyfD19fX0MOqt9mzZyMuLs7Qw6D/72GBKDk5GW+//fbjHRDVWXWBqEOHDkhOTkaHDh0e/6CeUmaGHgAZr2effdbQQ6iz0tJSKBQKmJk9GW/tP//8E6Wlpfj73/+Orl27Gno4j6x58+aGHgLVUqdOnQw9BHoE9vb2nEM94xYiqtaDm5PLy8vxySefwM/PD1ZWVmjUqBHatm2LFStWALi3W+X9998HAPj4+EChUOhs0i0vL8eiRYvwt7/9DUqlEmq1Gm+88QauXr2q87xCCMyfPx9eXl6wtLREx44dkZCQUGkTc8Um402bNmHatGnw8PCAUqnE+fPnkZOTgwkTJqB169awtbWFWq1G9+7dceTIEZ3nunjxIhQKBRYvXoyFCxfC29sbVlZWCA4OlsLKBx98AHd3d6hUKgwePBjZ2dm1ev2+//57BAUFwdraGnZ2dujZsyeSk5Ol5aNGjcKLL74IABgyZAgUCkWtNqHn5ubizTffhKOjI2xsbDBgwAD897//rVT35Zdfol27drC0tISjoyMGDx6MM2fO1Hmc1fnjjz/QrFkzBAYGSq9JVbt3FAoFJk2ahE2bNqFVq1awtrZGu3btsHPnzkp9fvfdd2jbti2USiWaNWuGFStWSLvraiM+Ph4hISFQqVSwtrZGq1atEB0dLS0/fvw4hg4dKs2zt7c3hg0bhkuXLun0U7Hr6uDBgxg/fjycnZ3h5OSEl19+GdevX6/0vFu3bkVQUBBsbW1ha2uL9u3bY/369To1+/btQ0hICOzt7WFtbY0XXngB+/fvr9V6Pejzzz9Hly5doFarYWNjA39/fyxatAilpaVSTXBwMHbt2oVLly5Jn8X7X8eqdpmdOnUKAwcOhIODAywtLdG+fXt89dVXOjUVn7uvv/4aH374Idzd3WFvb48ePXrg7NmzOrW//vorQkNDoVaroVQq4e7ujv79+1f6zFfnyJEj6NSpE6ysrODh4YHZs2ejrKwMwL2/Ey1btkTv3r0rPa6wsBAqlQoTJ06s1fPcLz8/H9OnT4ePjw8sLCzg4eGBiIgIFBUV6dTVZg4qxrlo0SLp71mHDh3w448/1mosCoUCRUVF+Oqrr6T5q/gbUdUus1GjRsHW1hZ//PEHevfuDRsbG7i5uWHBggUAgJSUFLz44ouwsbGBr69vpbkFgKysLIwbNw5NmjSBhYUFfHx8MHfuXNy9e7cOr+ITSpAsbNiwQQAQKSkporS0tNKtX79+wsvLS+cxXl5eYuTIkdL96OhoYWpqKubMmSP2798v4uPjxfLly0VUVJQQQogrV66IyZMnCwBi+/btIjk5WSQnJwuNRiOEEGLs2LECgJg0aZKIj48Xq1evFo0bNxaenp4iJydHep7IyEgBQIwdO1bEx8eLtWvXiqZNmwo3NzfRtWtXqe7gwYMCgPDw8BCvvvqq+P7778XOnTvFzZs3xR9//CHGjx8vYmNjxaFDh8TOnTvF6NGjhYmJiTh48KDUR0ZGhgAgvLy8xIABA8TOnTvF5s2bhYuLi/D19RXh4eHirbfeEj/++KNYvXq1sLW1FQMGDKjx9d6yZYsAIHr16iV27Nghtm3bJgICAoSFhYU4cuSIEEKI8+fPi88//1wAEPPnzxfJycni999/r3EOPT09pTH961//Emq1Wnh6eorc3Fypdv78+QKAGDZsmNi1a5fYuHGjaNasmVCpVOLPP/+s0ziFEGLOnDkCgDRPhw4dEg4ODmLgwIGiqKhIqhs5cmSl9xEA4e3tLZ5//nnx73//W+zevVsEBwcLMzMzceHCBanuxx9/FCYmJiI4OFjExcWJb775RgQGBgpvb29Rmz9V69atEwqFQgQHB4utW7eKffv2iS+++EJMmDBBqvnmm2/EP/7xDxEXFycSExNFbGys6Nq1q2jcuLHOe7DitW7WrJmYPHmy2LNnj1i3bp1wcHAQ3bp103ne2bNnCwDi5ZdfFt98843Yu3evWLp0qZg9e7ZUs2nTJqFQKMSgQYPE9u3bxQ8//CBCQ0OFqamp2LdvX6XnzcjIeOhr+t5774lVq1aJ+Ph4ceDAAbFs2TLh7Ows3nzzTanm999/Fy+88IJwdXWVPovJyck68zJnzhzp/h9//CHs7OxE8+bNxcaNG8WuXbvEsGHDBACxcOFCqa7ic+ft7S1GjBghdu3aJb7++mvRtGlT0bJlS3H37l0hhBCFhYXCyclJdOzYUfz73/8WiYmJYtu2beKdd94Rp0+ffuhcdu3aVTg5OQl3d3fxf//3f2LPnj1iypQpAoCYOHGiVLdixQqhUCh03tNCCOlz9bDPkxCV/8YVFRWJ9u3bC2dnZ7F06VKxb98+sWLFCqFSqUT37t1FeXl5neZAiP99dkaPHi19Zj08PISrq6vO37OqJCcnCysrK9GvXz9p/irWqWIe7v97NnLkSGFhYSFatWolVqxYIRISEsSbb74pAIjIyEjh6+sr1q9fL/bs2SNCQ0MFAHH8+HHp8ZmZmcLT01N4eXmJNWvWiH379omPP/5YKJVKMWrUqIeO9WnAQCQTFX9oH3arKRCFhoaK9u3bP/R5Fi9eXOkPuhBCnDlzRgDQ+XISQohjx44JAGLWrFlCCCFu3bollEqlGDJkiE5dcnKyAFBlIOrSpUuN63/37l1RWloqQkJCxODBg6X2ikDUrl07UVZWJrUvX75cABBhYWE6/URERAgAUsirSllZmXB3dxf+/v46fRYUFAi1Wi06d+5caR2++eabGtehYg7vH78QQvz0008CgPjkk0+EEELk5uZKf0Tvd/nyZaFUKsXw4cPrPM77A9GmTZuEhYWFmDJlis7jhKg+ELm4uIj8/HypLSsrS5iYmIjo6Gip7bnnnhOenp5Cq9XqjMXJyanGQFRQUCDs7e3Fiy++qPOlVZO7d++KwsJCYWNjI1asWCG1V7zWD75fFy1aJACIzMxMIYQQ//3vf4WpqakYMWJEtc9RVFQkHB0dKwXpsrIy0a5dO/H8889Xet6aAtGD/ZSWloqNGzcKU1NTcevWLWlZ//79q33sg4Fo6NChQqlUisuXL+vU9e3bV1hbW4u8vDwhxP/esw++v/79738LAFLoOn78uAAgduzYUe3Yq9O1a1cBQHz33Xc67WPGjBEmJibi0qVLQggh8vPzhZ2dnXj33Xd16lq3bl0puFalqn/0mZiYiNTUVJ26//znPwKA2L17d5X9VDcHubm5wtLSstrPbE2BSAghbGxsdMZYobpABEB8++23Ultpaalo3LixACB++eUXqf3mzZvC1NRUTJ06VWobN26csLW1lV7fCv/85z9rFTCfdNxlJjMbN25EampqpVvFrpuHef755/Hbb79hwoQJ2LNnD/Lz82v9vAcPHgSASmd0PP/882jVqpW06yAlJQVarRavv/66Tl2nTp2qPdPmlVdeqbJ99erV6NChAywtLWFmZgZzc3Ps37+/yt1G/fr1g4nJ/z4OrVq1AgD0799fp66i/fLly9WsKXD27Flcv34d4eHhOn3a2trilVdeQUpKCm7fvl3t42syYsQInfudO3eGl5eX9BonJyejuLi40mvt6emJ7t27S691fcb56aefYtSoUViwYAFWrFih87iH6datG+zs7KT7Li4uUKvV0q6qoqIiHD9+HIMGDYKFhYXOWAYMGFBj/0lJScjPz8eECRMeunutsLAQM2fORIsWLWBmZgYzMzPY2tqiqKioyvdFWFiYzv22bdsCgDTuhIQElJWVPXTXTFJSEm7duoWRI0fi7t270q28vBx9+vRBampqpd0xNfn1118RFhYGJycnmJqawtzcHG+88QbKysrw559/1qmvCgcOHEBISAg8PT112keNGoXbt29X2o1a02vTokULODg4YObMmVi9ejVOnz5dp/HY2dlVeo7hw4ejvLwchw8flmrefPNNxMTESK/hgQMHcPr0aUyaNKlOzwcAO3fuRJs2bdC+fXuduerdu3el3VO1mYPk5GTcuXOn2s9sQ1AoFOjXr59038zMDC1atICbm5vOcaGOjo46n8GK9e/WrRvc3d111r9v374AgMTExAYZs7FgIJKZVq1aoWPHjpVuKpWqxsdGRkbin//8J1JSUtC3b184OTkhJCSkVqeB37x5EwDg5uZWaZm7u7u0vOK/Li4uleqqaquuz6VLl2L8+PEIDAzEt99+i5SUFKSmpqJPnz4oLi6uVO/o6Khzv+JLubr2O3fuVDmW+9ehunUtLy9Hbm5utY+viaura5VtD76GtX2t6zLOzZs3w8PDA0OHDq3TmJ2cnCq1KZVKaS5yc3MhhKjTvN8vJycHANCkSZOH1g0fPhwrV67E22+/jT179uDnn39GamoqGjduXOX74sFxK5VKAJBqa/O8N27cAAC8+uqrMDc317ktXLgQQgjcunWrxnWscPnyZbz00ku4du0aVqxYgSNHjiA1NRWff/65ztjq6ubNm9W+FyqW36+m10alUiExMRHt27fHrFmz8Mwzz8Dd3R1z5sypdJxNVaqa94r3/v1jmTx5MgoKCrBlyxYAwMqVK9GkSRMMHDiwxud40I0bN3DixIlK82RnZwchhHTZidrOQcU4q/vMNgRra2tYWlrqtFlYWFT6W1bRfv/fshs3buCHH36otP7PPPMMANR42Y0n3ZNxKg4ZBTMzM0ydOhVTp05FXl4e9u3bh1mzZqF37964cuUKrK2tq31sxR/PzMzMSl8e169fh7Ozs05dxZfI/bKysqrcSlTVFoHNmzcjODgYq1at0mkvKCh4+Erqwf3r+qDr16/DxMQEDg4O9e4/KyuryrYWLVrU6vkffK3rMs74+HgMGTIEL730Evbv36+3f+U6ODhAoVBUO+81ady4MQA89GBdjUaDnTt3Ys6cOfjggw+kdq1WW6dAUt3zPrhlpULF6/3ZZ59Ve1ZQbUJfhR07dqCoqAjbt2/Xef2ru35VbTk5OVX7XgD+tx514e/vj9jYWAghcOLECcTExGDevHmwsrLSmYOqPOy9cH8Ya9GiBfr27YvPP/8cffv2xffff4+5c+fC1NS0zuN1dnaGlZUVvvzyy2qXA7Wfg4pxVveZNbZrdjk7O6Nt27b49NNPq1xeEY6fVtxCRPXSqFEjvPrqq5g4cSJu3bolXUjuwX8lVujevTuAe0HlfqmpqThz5gxCQkIAAIGBgVAqldi2bZtOXUpKSqUzgR5GoVBIY6lw4sSJWp099aj8/Pzg4eGBrVu3QgghtRcVFeHbb7+Vzuiqr4p/CVdISkrCpUuXpLNPgoKCYGVlVem1vnr1qrRbpL7j9PLywpEjR6BUKvHSSy/h3Llz9V6P+9nY2KBjx47YsWMHSkpKpPbCwsIqz0Z7UOfOnaFSqbB69WqddbmfQqGAEKLS+2LdunXSmUt11atXL5iamlYK3vd74YUX0KhRI5w+fbrKrbMdO3bU2U1Yk4p/ANy/HkIIrF27tlLt/VvhahISEoIDBw5UOotu48aNsLa2fqRTvBUKBdq1a4dly5ahUaNG+OWXX2p8TEFBAb7//nudtq1bt8LExARdunTRaX/33Xdx4sQJjBw5EqamphgzZky9xhkaGooLFy7AycmpynmqCDC1nYNOnTrB0tKy2s9sbdRlDh9VaGgoTp06hebNm1e5/k97IOIWIqq1AQMGoE2bNujYsSMaN26MS5cuYfny5fDy8kLLli0B3PsXIQCsWLECI0eOhLm5Ofz8/ODn54exY8fis88+g4mJCfr27YuLFy9i9uzZ8PT0xHvvvQfg3i6qqVOnIjo6Gg4ODhg8eDCuXr2KuXPnws3NrdbHrISGhuLjjz/GnDlz0LVrV5w9exbz5s2Dj49Pg58+amJigkWLFmHEiBEIDQ3FuHHjoNVqsXjxYuTl5UmnwNbX8ePH8fbbb+O1117DlStX8OGHH8LDwwMTJkwAcC+szp49G7NmzcIbb7yBYcOG4ebNm5g7dy4sLS0xZ86cRxqnm5sbEhMT0bt3b3Tp0gUJCQl6uarwvHnz0L9/f/Tu3RvvvvsuysrKsHjxYtja2ta4BcfW1hZLlizB22+/jR49emDMmDFwcXHB+fPn8dtvv2HlypWwt7dHly5dsHjxYjg7O8Pb2xuJiYlYv349GjVqVK8xe3t7Y9asWfj4449RXFyMYcOGQaVS4fTp0/jrr78wd+5c2Nra4rPPPsPIkSNx69YtvPrqq1Cr1cjJycFvv/2GnJychwaqB/Xs2RMWFhYYNmwYZsyYgTt37mDVqlVV7ob19/fH9u3bsWrVKgQEBMDExAQdO3asst85c+ZIx5D84x//gKOjI7Zs2YJdu3Zh0aJFtdqtfr+dO3fiiy++wKBBg9CsWTMIIbB9+3bk5eWhZ8+eNT7eyckJ48ePx+XLl+Hr64vdu3dj7dq1GD9+PJo2bVrpNWndujUOHjyIv//971Cr1XUaa4WIiAh8++236NKlC9577z20bdsW5eXluHz5Mvbu3Ytp06YhMDCw1nPg4OCA6dOn45NPPtH5zEZFRdV6l5m/vz8OHTqEH374AW5ubrCzs4Ofn1+91q8m8+bNQ0JCAjp37owpU6bAz88Pd+7cwcWLF7F7926sXr26xt3STzQDHcxNj1nF2SsPnj1RoaqzUR48A2PJkiWic+fOwtnZWVhYWIimTZuK0aNHi4sXL+o8LjIyUri7uwsTExOdsyDKysrEwoULha+vrzA3NxfOzs7i73//u7hy5YrO48vLy8Unn3wimjRpIiwsLETbtm3Fzp07Rbt27XTO1njYGVparVZMnz5deHh4CEtLS9GhQwexY8eOSmfsVJxltnjxYp3HV9d3Ta/j/Xbs2CECAwOFpaWlsLGxESEhIeKnn36q1fNUpeK59+7dK8LDw0WjRo2ks8nOnTtXqX7dunWibdu2wsLCQqhUKjFw4MAqzxKpzTgfPO1eCCHy8vLECy+8IBwdHaXXo7qzzO4/VbrCg+8vIYSIi4sT/v7+0vtrwYIFYsqUKcLBwaHG10cIIXbv3i26du0qbGxshLW1tWjdurXOKeNXr14Vr7zyinBwcBB2dnaiT58+4tSpU5XGUt08V3VmjxBCbNy4UTz33HPC0tJS2NraimeffVZs2LBBpyYxMVH0799fODo6CnNzc+Hh4SH69++vM/e1Pcvshx9+EO3atROWlpbCw8NDvP/+++LHH3+sNLZbt26JV199VTRq1EgoFAqds/XwwFlmQghx8uRJMWDAAKFSqYSFhYVo165dpfWo7j1b8VmqqP/jjz/EsGHDRPPmzYWVlZVQqVTi+eefFzExMaImXbt2Fc8884w4dOiQ6Nixo1AqlcLNzU3MmjVLlJaWVvmYqKgo6dIitVXVe7CwsFB89NFHws/PT/rs+Pv7i/fee09kZWVJdbWdg/LychEdHS08PT2lv2c//PCD6Nq1a63OMktPTxcvvPCCsLa21jkzrbqzzGxsbCr1UfF6VrX+/fv312nLyckRU6ZMET4+PsLc3Fw4OjqKgIAA8eGHH4rCwsIax/skUwhRzfZlIiOSkZGBv/3tb5gzZw5mzZpl6OHQY1JaWor27dvDw8MDe/fuNfRwyIh17NgRCoUCqamphh4KPaG4y4yMzm+//Yavv/4anTt3hr29Pc6ePYtFixbB3t4eo0ePNvTwqAGNHj0aPXv2hJubG7KysrB69WqcOXNGuho60f3y8/Nx6tQp7Ny5E2lpafwdPXokDERkdGxsbHD8+HGsX78eeXl5UKlUCA4Oxqefflqns3HoyVNQUIDp06cjJycH5ubm6NChA3bv3o0ePXoYemhkhH755Rd069YNTk5OmDNnDgYNGmToIdETjLvMiIiISPZ42j0RERHJHgMRERERyR4DEREREckeD6qupfLycly/fh12dnYP/fFIIiIiMh5CCBQUFMDd3f2hF/dlIKql69evV/tbRURERGTcrly58tArbTMQ1ZKdnR2Aey+ovb29gUdDREREtZGfnw9PT0/pe7w6DES1VLGbzN7enoGIiIjoCVPT4S48qJqIiIhkj4GIiIiIZI+BiIiIiGSPxxDpWVlZGUpLSw09DKonc3NzmJqaGnoYRET0mDEQ6YkQAllZWcjLyzP0UOgRNWrUCK6urrzeFBGRjDAQ6UlFGFKr1bC2tuaX6RNICIHbt28jOzsbAODm5mbgERER0ePCQKQHZWVlUhhycnIy9HDoEVhZWQEAsrOzoVarufuMiEgmeFC1HlQcM2RtbW3gkZA+VMwjjwUjIpIPBiI94m6ypwPnkYhIfhiIiIiISPYYiGQsODgYERERhh4GERGRwfGg6ga0LOHPx/p87/X0fazPV5Pg4GC0b98ey5cvN/RQiIiIHopbiIiIiEj2GIhIEh8fD5VKhY0bN+LatWsYMmQIHBwc4OTkhIEDB+LixYtS7ahRozBo0CDMnTsXarUa9vb2GDduHEpKSqTliYmJWLFiBRQKBRQKhc7jiYiIjAkDEQEAYmNj8frrr2Pjxo149dVX0a1bN9ja2uLw4cM4evQobG1t0adPHynwAMD+/ftx5swZHDx4EF9//TXi4uIwd+5cAMCKFSsQFBSEMWPGIDMzE5mZmfD09DTU6hERET0UjyEyBtoC/fSTn3nvv/Z1u8LyF198gVmzZuG7775Dt27d8OWXX8LExATr1q2TTkHfsGEDGjVqhEOHDqFXr14AAAsLC3z55ZewtrbGM888g3nz5uH999/Hxx9/DJVKBQsLC1hbW8PV1VU/60dERNRAGIhk7ttvv8WNGzdw9OhRPP/88wCAtLQ0nD9/HnZ2djq1d+7cwYULF6T77dq107kYZVBQEAoLC3HlyhV4eXk9nhUgIiLSA4PuMlu1ahXatm0Le3t72NvbIygoCD/++KO0XAiBqKgouLu7w8rKCsHBwfj99991+tBqtZg8eTKcnZ1hY2ODsLAwXL16VacmNzcX4eHhUKlUUKlUCA8P54+w/n/t27dH48aNsWHDBgghAADl5eUICAhAenq6zu3PP//E8OHDa+yTFzYkIqInjUEDUZMmTbBgwQIcP34cx48fR/fu3TFw4EAp9CxatAhLly7FypUrkZqaCldXV/Ts2RMFBf/bxRQREYG4uDjExsbi6NGjKCwsRGhoKMrKyqSa4cOHIz09HfHx8YiPj0d6ejrCw8Mf+/oao+bNm+PgwYP47rvvMHnyZABAhw4dcO7cOajVarRo0ULnplKppMf+9ttvKC4ulu6npKTA1tYWTZo0AXBvl9r980BERGSsDBqIBgwYgH79+sHX1xe+vr749NNPYWtri5SUFAghsHz5cnz44Yd4+eWX0aZNG3z11Ve4ffs2tm7dCgDQaDRYv349lixZgh49euDZZ5/F5s2bcfLkSezbtw8AcObMGcTHx2PdunUICgpCUFAQ1q5di507d+Ls2bOGXH2j4evri4MHD+Lbb79FREQERowYAWdnZwwcOBBHjhxBRkYGEhMT8e677+psfSspKcHo0aNx+vRp/Pjjj5gzZw4mTZoEE5N7bytvb28cO3YMFy9exF9//YXy8nJDrSIREdFDGc0xRGVlZfjmm29QVFSEoKAgZGRkICsrSzqAFwCUSiW6du2KpKQkjBs3DmlpaSgtLdWpcXd3R5s2bZCUlITevXsjOTkZKpUKgYGBUk2nTp2gUqmQlJQEPz+/Ksej1Wqh1Wql+/n5+XVep1pfKLHiYGgD8vPzw4EDBxAcHAxTU1McPnwYM2fOxMsvv4yCggJ4eHggJCQE9vb20mNCQkLQsmVLdOnSBVqtFkOHDkVUVJS0fPr06Rg5ciRat26N4uJiZGRkwNvb+/GvHBERUQ0MHohOnjyJoKAg3LlzB7a2toiLi0Pr1q2RlJQEAHBxcdGpd3FxwaVLlwAAWVlZsLCwgIODQ6WarKwsqUatVld6XrVaLdVUJTo6WjqF/Gl16NAhnfutWrXCjRs3pPtfffVVjX3MnTu32tfJ19cXycnJjzRGIiKix8Hg1yHy8/NDeno6UlJSMH78eIwcORKnT5+Wlj94gK4QosaDdh+sqaq+pn4iIyOh0Wik25UrV2q7SkRERPSEMXggsrCwQIsWLdCxY0dER0ejXbt2WLFihXTtmge34mRnZ0tbjVxdXVFSUoLc3NyH1ty/1aNCTk5Opa1P91MqldLZbxU3IiIiejoZPBA9SAgBrVYLHx8fuLq6IiEhQVpWUlKCxMREdO7cGQAQEBAAc3NznZrMzEycOnVKqgkKCoJGo8HPP/8s1Rw7dgwajUaqobqLiYnBjh07DD0MIiIivTDoMUSzZs1C37594enpiYKCAsTGxuLQoUOIj4+HQqFAREQE5s+fj5YtW6Jly5aYP38+rK2tpWvhqFQqjB49GtOmTYOTkxMcHR0xffp0+Pv7o0ePHgDuHRfTp08fjBkzBmvWrAEAjB07FqGhodUeUE1ERETyYtBAdOPGDYSHhyMzMxMqlQpt27ZFfHw8evbsCQCYMWMGiouLMWHCBOTm5iIwMBB79+7VuYLysmXLYGZmhtdffx3FxcUICQlBTEwMTE1NpZotW7ZgypQp0tloYWFhWLly5eNdWSIiIjJaClFxeWJ6qPz8fKhUKmg0mkrHE925cwcZGRnw8fGBpaVlPTrX82n3dfwtM9L1yPNJRERG42Hf3/czumOIiIiIiB43BiIiIiKSPQYiIiIikj0GIjJqo0aNwqBBg6T7wcHBiIiIeKQ+Y2Ji0KhRo0fqg4iIni4G/+mOp9rB6NrVaQv083ydJ+unHyIiIpnhFiIiIiKSPQYimSsvL8fChQvRokULKJVKNG3aFJ9++ikAYObMmfD19YW1tTWaNWuG2bNno7S0VHpsVFQU2rdvj02bNsHb2xsqlQpDhw5FQUFBrfoHgGvXrmHIkCFwcHCAk5MTBg4ciIsXL9Z6/CUlJZgxYwY8PDxgY2ODwMDASj9aGxMTg6ZNm8La2hqDBw/GzZs36/diERHRU4uBSOYiIyOxcOFCzJ49G6dPn8bWrVul33izs7NDTEwMTp8+jRUrVmDt2rVYtmyZzuMvXLiAHTt2YOfOndi5cycSExOxYMGCWvV/+/ZtdOvWDba2tjh8+DCOHj0KW1tb9OnTByUlJbUa/5tvvomffvoJsbGxOHHiBF577TX06dMH586dA3DvZ1reeustTJgwAenp6ejWrRs++eQTfbx0RET0FOExRDJWUFCAFStWYOXKlRg5ciQAoHnz5njxxRcBAB999JFU6+3tjWnTpmHbtm2YMWOG1F5eXo6YmBjp6uHh4eHYv38/Pv300xr7j42NhYmJCdatWweFQgEA2LBhAxo1aoRDhw5JVxavzoULF/D111/j6tWrcHd3BwBMnz4d8fHx2LBhA+bPn48VK1agd+/e+OCDDwAAvr6+SEpKQnx8/CO/fkRE9PRgIJKxM2fOQKvVIiQkpMrl//nPf7B8+XKcP38ehYWFuHv3bqWrfHp7e+v8lIqbmxuys7Nr1X9aWhrOnz+v83jg3pWiL1y4UOP4f/nlFwgh4Ovrq9Ou1Wrh5OQkjWHw4ME6y4OCghiIiIhIBwORjFlZWVW7LCUlBUOHDsXcuXPRu3dvqFQqxMbGYsmSJTp15ubmOvcVCgXKy8tr7B+4t3UpICAAW7ZsqbSscePGNY6/vLwcpqamSEtL0/ntOgCwtbUFAPCXaYiIqDYYiGSsZcuWsLKywv79+/H222/rLPvpp5/g5eWFDz/8UGq7dOmS3voHgA4dOmDbtm1Qq9UP/X2Z6jz77LMoKytDdnY2XnrppSprWrdujZSUFJ22B+8TERExEMmYpaUlZs6ciRkzZsDCwgIvvPACcnJy8Pvvv6NFixa4fPkyYmNj8dxzz2HXrl2Ii4vTW/+jR4/GiBEjsHjxYgwcOBDz5s1DkyZNcPnyZWzfvh3vv/8+mjRp8tD+fX19MWLECLzxxhtYsmQJnn32Wfz11184cOAA/P390a9fP0yZMgWdO3fGokWLMGjQIOzdu5e7y4iIqBIGoobULbJ2dfr+tfs6mD17NszMzPCPf/wD169fh5ubG9555x2MHj0a7733HiZNmgStVov+/ftj9uzZiIqK0kv/AGBtbY3Dhw9j5syZePnll1FQUAAPDw+EhITUeovRhg0b8Mknn2DatGm4du0anJycEBQUhH79+gEAOnXqhHXr1mHOnDmIiopCjx498NFHH+Hjjz+u03oQEdHTTSF4kEWt5OfnQ6VSQaPRVPqyvnPnDjIyMuDj4wNLS8t6dK7nQGTvpt/+ZOaR55OIiIzGw76/78frEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRDpEY9PfzpwHomI5IeBSA8qrtZ8+/ZtA4+E9KFiHh+8CjcRET29eB0iPTA1NUWjRo2k3/CytraWfqy0VkpK9TugO3f0259MCCFw+/ZtZGdno1GjRpV+DoSIiJ5eDER64urqCgBSKKqTOxr9DsaySL/9yUyjRo2k+SQiInlgINIThUIBNzc3qNVqlJbWcYvPsTX6HUyrcfrtT0bMzc25ZYiISIYYiPTM1NS07l+o5Xo+9ohXVyYiIqoTHlRNREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREsmfQQBQdHY3nnnsOdnZ2UKvVGDRoEM6ePatTM2rUKCgUCp1bp06ddGq0Wi0mT54MZ2dn2NjYICwsDFevXtWpyc3NRXh4OFQqFVQqFcLDw5GXl9fQq0hERERPAIMGosTEREycOBEpKSlISEjA3bt30atXLxQVFenU9enTB5mZmdJt9+7dOssjIiIQFxeH2NhYHD16FIWFhQgNDUVZWZlUM3z4cKSnpyM+Ph7x8fFIT09HeHj4Y1lPIiIiMm5mhnzy+Ph4nfsbNmyAWq1GWloaunTpIrUrlUq4urpW2YdGo8H69euxadMm9OjRAwCwefNmeHp6Yt++fejduzfOnDmD+Ph4pKSkIDAwEACwdu1aBAUF4ezZs/Dz82ugNSQiIqIngVEdQ6TRaAAAjo6OOu2HDh2CWq2Gr68vxowZg+zsbGlZWloaSktL0atXL6nN3d0dbdq0QVJSEgAgOTkZKpVKCkMA0KlTJ6hUKqnmQVqtFvn5+To3IiIiejoZTSASQmDq1Kl48cUX0aZNG6m9b9++2LJlCw4cOIAlS5YgNTUV3bt3h1arBQBkZWXBwsICDg4OOv25uLggKytLqlGr1ZWeU61WSzUPio6Olo43UqlU8PT01NeqEhERkZEx6C6z+02aNAknTpzA0aNHddqHDBki/X+bNm3QsWNHeHl5YdeuXXj55Zer7U8IAYVCId2///+rq7lfZGQkpk6dKt3Pz89nKCIiInpKGcUWosmTJ+P777/HwYMH0aRJk4fWurm5wcvLC+fOnQMAuLq6oqSkBLm5uTp12dnZcHFxkWpu3LhRqa+cnByp5kFKpRL29vY6NyIiIno6GTQQCSEwadIkbN++HQcOHICPj0+Nj7l58yauXLkCNzc3AEBAQADMzc2RkJAg1WRmZuLUqVPo3LkzACAoKAgajQY///yzVHPs2DFoNBqphoiIiOTLoLvMJk6ciK1bt+K7776DnZ2ddDyPSqWClZUVCgsLERUVhVdeeQVubm64ePEiZs2aBWdnZwwePFiqHT16NKZNmwYnJyc4Ojpi+vTp8Pf3l846a9WqFfr06YMxY8ZgzZo1AICxY8ciNDSUZ5gRERGRYQPRqlWrAADBwcE67Rs2bMCoUaNgamqKkydPYuPGjcjLy4Obmxu6deuGbdu2wc7OTqpftmwZzMzM8Prrr6O4uBghISGIiYmBqampVLNlyxZMmTJFOhstLCwMK1eubPiVJCIiIqOnEEIIQw/iSZCfnw+VSgWNRqP/44kORuu3v26R+u2PiIjoCVXb72+jOKiaiIiIyJAYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYMGoiio6Px3HPPwc7ODmq1GoMGDcLZs2d1aoQQiIqKgru7O6ysrBAcHIzff/9dp0ar1WLy5MlwdnaGjY0NwsLCcPXqVZ2a3NxchIeHQ6VSQaVSITw8HHl5eQ29ikRERPQEMGggSkxMxMSJE5GSkoKEhATcvXsXvXr1QlFRkVSzaNEiLF26FCtXrkRqaipcXV3Rs2dPFBQUSDURERGIi4tDbGwsjh49isLCQoSGhqKsrEyqGT58ONLT0xEfH4/4+Hikp6cjPDz8sa4vERERGSeFEEIYehAVcnJyoFarkZiYiC5dukAIAXd3d0RERGDmzJkA7m0NcnFxwcKFCzFu3DhoNBo0btwYmzZtwpAhQwAA169fh6enJ3bv3o3evXvjzJkzaN26NVJSUhAYGAgASElJQVBQEP744w/4+fnVOLb8/HyoVCpoNBrY29vrd8UPRuu3v26R+u2PiIjoCVXb72+jOoZIo9EAABwdHQEAGRkZyMrKQq9evaQapVKJrl27IikpCQCQlpaG0tJSnRp3d3e0adNGqklOToZKpZLCEAB06tQJKpVKqiEiIiL5MjP0ACoIITB16lS8+OKLaNOmDQAgKysLAODi4qJT6+LigkuXLkk1FhYWcHBwqFRT8fisrCyo1epKz6lWq6WaB2m1Wmi1Wul+fn5+PdeMiIiIjJ3RbCGaNGkSTpw4ga+//rrSMoVCoXNfCFGp7UEP1lRV/7B+oqOjpQOwVSoVPD09a7MaRERE9AQyikA0efJkfP/99zh48CCaNGkitbu6ugJApa042dnZ0lYjV1dXlJSUIDc396E1N27cqPS8OTk5lbY+VYiMjIRGo5FuV65cqf8KEhERkVEzaCASQmDSpEnYvn07Dhw4AB8fH53lPj4+cHV1RUJCgtRWUlKCxMREdO7cGQAQEBAAc3NznZrMzEycOnVKqgkKCoJGo8HPP/8s1Rw7dgwajUaqeZBSqYS9vb3OjYiIiJ5OBj2GaOLEidi6dSu+++472NnZSVuCVCoVrKysoFAoEBERgfnz56Nly5Zo2bIl5s+fD2trawwfPlyqHT16NKZNmwYnJyc4Ojpi+vTp8Pf3R48ePQAArVq1Qp8+fTBmzBisWbMGADB27FiEhobW6gwzIiIieroZNBCtWrUKABAcHKzTvmHDBowaNQoAMGPGDBQXF2PChAnIzc1FYGAg9u7dCzs7O6l+2bJlMDMzw+uvv47i4mKEhIQgJiYGpqamUs2WLVswZcoU6Wy0sLAwrFy5smFXkIiIiJ4IRnUdImPG6xARERE9eZ7I6xARERERGQIDEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyV69AlH37t2Rl5dXqT0/Px/du3d/1DERERERPVb1CkSHDh1CSUlJpfY7d+7gyJEjjzwoIiIiosfJrC7FJ06ckP7/9OnTyMrKku6XlZUhPj4eHh4e+hsdERER0WNQp0DUvn17KBQKKBSKKneNWVlZ4bPPPtPb4IiIiIgehzoFooyMDAgh0KxZM/z8889o3LixtMzCwgJqtRqmpqZ6HyQRERFRQ6pTIPLy8gIAlJeXN8hgiIiIiAyhToHofn/++ScOHTqE7OzsSgHpH//4xyMPjIiIiOhxqVcgWrt2LcaPHw9nZ2e4urpCoVBIyxQKBQMRERERPVHqFYg++eQTfPrpp5g5c6a+x0NERET02NXrOkS5ubl47bXX9D0WIiIiIoOoVyB67bXXsHfvXn2PhYiIiMgg6rXLrEWLFpg9ezZSUlLg7+8Pc3NzneVTpkzRy+CIiIiIHgeFEELU9UE+Pj7Vd6hQ4L///e8jDcoY5efnQ6VSQaPRwN7eXr+dH4zWb3/dIvXbHxER0ROqtt/f9dpClJGRUe+BERERERmbeh1DRERERPQ0qdcWorfeeuuhy7/88st6DYaIiIjIEOoViHJzc3Xul5aW4tSpU8jLy6vyR1+JiIiIjFm9AlFcXFyltvLyckyYMAHNmjV75EERERERPU56O4bIxMQE7733HpYtW6avLomIiIgeC70eVH3hwgXcvXtXn10SERERNbh67TKbOnWqzn0hBDIzM7Fr1y6MHDlSLwMjIiIielzqFYh+/fVXnfsmJiZo3LgxlixZUuMZaERERETGpl6B6ODBg/oeBxEREZHB1CsQVcjJycHZs2ehUCjg6+uLxo0b62tcRERERI9NvQ6qLioqwltvvQU3Nzd06dIFL730Etzd3TF69Gjcvn1b32MkIiIialD1CkRTp05FYmIifvjhB+Tl5SEvLw/fffcdEhMTMW3atFr3c/jwYQwYMADu7u5QKBTYsWOHzvJRo0ZBoVDo3Dp16qRTo9VqMXnyZDg7O8PGxgZhYWG4evWqTk1ubi7Cw8OhUqmgUqkQHh6OvLy8+qw6ERERPYXqFYi+/fZbrF+/Hn379oW9vT3s7e3Rr18/rF27Fv/5z39q3U9RURHatWuHlStXVlvTp08fZGZmSrfdu3frLI+IiEBcXBxiY2Nx9OhRFBYWIjQ0FGVlZVLN8OHDkZ6ejvj4eMTHxyM9PR3h4eF1X3EiIiJ6KtXrGKLbt2/DxcWlUrtara7TLrO+ffuib9++D61RKpVwdXWtcplGo8H69euxadMm9OjRAwCwefNmeHp6Yt++fejduzfOnDmD+Ph4pKSkIDAwEACwdu1aBAUF4ezZs/Dz86v1eImIiOjpVK8tREFBQZgzZw7u3LkjtRUXF2Pu3LkICgrS2+AA4NChQ1Cr1fD19cWYMWOQnZ0tLUtLS0NpaSl69eoltbm7u6NNmzZISkoCACQnJ0OlUklhCAA6deoElUol1VRFq9UiPz9f50ZERERPp3ptIVq+fDn69u2LJk2aoF27dlAoFEhPT4dSqcTevXv1Nri+ffvitddeg5eXFzIyMjB79mx0794daWlpUCqVyMrKgoWFBRwcHHQe5+LigqysLABAVlYW1Gp1pb7VarVUU5Xo6GjMnTtXb+tCRERExqtegcjf3x/nzp3D5s2b8ccff0AIgaFDh2LEiBGwsrLS2+CGDBki/X+bNm3QsWNHeHl5YdeuXXj55ZerfZwQAgqFQrp///9XV/OgyMhInSty5+fnw9PTs66rQERERE+AegWi6OhouLi4YMyYMTrtX375JXJycjBz5ky9DO5Bbm5u8PLywrlz5wAArq6uKCkpQW5urs5WouzsbHTu3FmquXHjRqW+cnJyqjwOqoJSqYRSqdTzGhAREZExqtcxRGvWrMHf/va3Su3PPPMMVq9e/ciDqs7Nmzdx5coVuLm5AQACAgJgbm6OhIQEqSYzMxOnTp2SAlFQUBA0Gg1+/vlnqebYsWPQaDRSDREREclbvbYQZWVlSaHkfo0bN0ZmZmat+yksLMT58+el+xkZGUhPT4ejoyMcHR0RFRWFV155BW5ubrh48SJmzZoFZ2dnDB48GACgUqkwevRoTJs2DU5OTnB0dMT06dPh7+8vnXXWqlUr9OnTB2PGjMGaNWsAAGPHjkVoaCjPMCMiIiIA9QxEnp6e+Omnn+Dj46PT/tNPP8Hd3b3W/Rw/fhzdunWT7lccszNy5EisWrUKJ0+exMaNG5GXlwc3Nzd069YN27Ztg52dnfSYZcuWwczMDK+//jqKi4sREhKCmJgYmJqaSjVbtmzBlClTpLPRwsLCHnrtIyIiIpKXegWit99+GxERESgtLUX37t0BAPv378eMGTPqdKXq4OBgCCGqXb5nz54a+7C0tMRnn32Gzz77rNoaR0dHbN68udbjIiIiInmpVyCaMWMGbt26hQkTJqCkpATAvWAyc+ZMREZG6nWARERERA2tXoFIoVBg4cKFmD17Ns6cOQMrKyu0bNmSZ2URERHRE6legaiCra0tnnvuOX2NhYiIiMgg6nXaPREREdHThIGIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZM/M0AOgBnAwWr/9dYvUb39ERERGhluIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYMGogOHz6MAQMGwN3dHQqFAjt27NBZLoRAVFQU3N3dYWVlheDgYPz+++86NVqtFpMnT4azszNsbGwQFhaGq1ev6tTk5uYiPDwcKpUKKpUK4eHhyMvLa+C1IyIioieFQQNRUVER2rVrh5UrV1a5fNGiRVi6dClWrlyJ1NRUuLq6omfPnigoKJBqIiIiEBcXh9jYWBw9ehSFhYUIDQ1FWVmZVDN8+HCkp6cjPj4e8fHxSE9PR3h4eIOvHxERET0ZFEIIYehBAIBCoUBcXBwGDRoE4N7WIXd3d0RERGDmzJkA7m0NcnFxwcKFCzFu3DhoNBo0btwYmzZtwpAhQwAA169fh6enJ3bv3o3evXvjzJkzaN26NVJSUhAYGAgASElJQVBQEP744w/4+fnVanz5+flQqVTQaDSwt7fX78ofjNZvf/rWLdLQIyAiIqqX2n5/G+0xRBkZGcjKykKvXr2kNqVSia5duyIpKQkAkJaWhtLSUp0ad3d3tGnTRqpJTk6GSqWSwhAAdOrUCSqVSqohIiIieTMz9ACqk5WVBQBwcXHRaXdxccGlS5ekGgsLCzg4OFSqqXh8VlYW1Gp1pf7VarVUUxWtVgutVivdz8/Pr9+KEBERkdEz2i1EFRQKhc59IUSltgc9WFNVfU39REdHSwdhq1QqeHp61nHkRERE9KQw2kDk6uoKAJW24mRnZ0tbjVxdXVFSUoLc3NyH1ty4caNS/zk5OZW2Pt0vMjISGo1Gul25cuWR1oeIiIiMl9EGIh8fH7i6uiIhIUFqKykpQWJiIjp37gwACAgIgLm5uU5NZmYmTp06JdUEBQVBo9Hg559/lmqOHTsGjUYj1VRFqVTC3t5e50ZERERPJ4MeQ1RYWIjz589L9zMyMpCeng5HR0c0bdoUERERmD9/Plq2bImWLVti/vz5sLa2xvDhwwEAKpUKo0ePxrRp0+Dk5ARHR0dMnz4d/v7+6NGjBwCgVatW6NOnD8aMGYM1a9YAAMaOHYvQ0NBan2Eme/o8C45nrBERkREyaCA6fvw4unXrJt2fOnUqAGDkyJGIiYnBjBkzUFxcjAkTJiA3NxeBgYHYu3cv7OzspMcsW7YMZmZmeP3111FcXIyQkBDExMTA1NRUqtmyZQumTJkinY0WFhZW7bWPiIiISH6M5jpExk7W1yHSJ24hIiKix+iJvw4RERER0ePCQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLJntL92T08pfV9zidc1IiIiPeAWIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPTNDD4DokRyM1m9/3SL12x8RET0RuIWIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkz6gDUVRUFBQKhc7N1dVVWi6EQFRUFNzd3WFlZYXg4GD8/vvvOn1otVpMnjwZzs7OsLGxQVhYGK5evfq4V4WIiIiMmFEHIgB45plnkJmZKd1OnjwpLVu0aBGWLl2KlStXIjU1Fa6urujZsycKCgqkmoiICMTFxSE2NhZHjx5FYWEhQkNDUVZWZojVISIiIiNk9BdmNDMz09kqVEEIgeXLl+PDDz/Eyy+/DAD46quv4OLigq1bt2LcuHHQaDRYv349Nm3ahB49egAANm/eDE9PT+zbtw+9e/d+rOtCRERExsnotxCdO3cO7u7u8PHxwdChQ/Hf//4XAJCRkYGsrCz06tVLqlUqlejatSuSkpIAAGlpaSgtLdWpcXd3R5s2baSa6mi1WuTn5+vciIiI6Olk1IEoMDAQGzduxJ49e7B27VpkZWWhc+fOuHnzJrKysgAALi4uOo9xcXGRlmVlZcHCwgIODg7V1lQnOjoaKpVKunl6eupxzYiIiMiYGHUg6tu3L1555RX4+/ujR48e2LVrF4B7u8YqKBQKnccIISq1Pag2NZGRkdBoNNLtypUr9VwLIiIiMnZGfwzR/WxsbODv749z585h0KBBAO5tBXJzc5NqsrOzpa1Grq6uKCkpQW5urs5WouzsbHTu3Pmhz6VUKqFUKvW/ElVI/u/NBus7qJlTg/VNRET0tDDqLUQP0mq1OHPmDNzc3ODj4wNXV1ckJCRIy0tKSpCYmCiFnYCAAJibm+vUZGZm4tSpUzUGIiIiIpIPo95CNH36dAwYMABNmzZFdnY2PvnkE+Tn52PkyJFQKBSIiIjA/Pnz0bJlS7Rs2RLz58+HtbU1hg8fDgBQqVQYPXo0pk2bBicnJzg6OmL69OnSLjgiIiIiwMgD0dWrVzFs2DD89ddfaNy4MTp16oSUlBR4eXkBAGbMmIHi4mJMmDABubm5CAwMxN69e2FnZyf1sWzZMpiZmeH1119HcXExQkJCEBMTA1NTU0OtFhERERkZhRBCGHoQT4L8/HyoVCpoNBrY29vrte/k9dP12t/9eAxRHXWLNPQIiIhIj2r7/f1EHUNERERE1BAYiIiIiEj2GIiIiIhI9oz6oGqix+5gtP764vFIRERPDG4hIiIiItnjFqKnXENdBZtnrxER0dOEgYiooehz9xvAXXBERA2Iu8yIiIhI9riFiOqFP0hLRERPE24hIiIiItljICIiIiLZ4y4zkhWedfc/yxL+bLC+3+vp22B9ExE1BG4hIiIiItljICIiIiLZ4y4zItK7htodx11xRNRQuIWIiIiIZI+BiIiIiGSPgYiIiIhkj8cQkdFpyKtgP9H0+dto/F00IiIdDEREesCfMiEierJxlxkRERHJHgMRERERyR4DEREREckeAxERERHJHg+qJiJqQPwRXaInA7cQERERkewxEBEREZHscZcZkZFriGscpdxtuN049PjwR3SJ9IeBiIieGDweh4gaCneZERERkewxEBEREZHscZcZERHp4K5JkiNuISIiIiLZYyAiIiIi2eMuMyIZ6nT5X3rtL6XpWL32R0T0uHELEREREckeAxERERHJHneZEdEj4y44InrScQsRERERyR63EBERoWGvvUNExo+BiIiMjj53wXH3m3HhRR/JWHGXGREREcketxAR0VONB3wTUW0wEBERGRB3DxIZB+4yIyIiItnjFiIioqcEdw8+eRrqIHMeYF53sgpEX3zxBRYvXozMzEw888wzWL58OV566SVDD4uIniD6Dh1ywt2DZMxkE4i2bduGiIgIfPHFF3jhhRewZs0a9O3bF6dPn0bTpk0NPTwiIqNjzOGvqrElr69/fw8LWNzaIg+yCURLly7F6NGj8fbbbwMAli9fjj179mDVqlWIjo428OiIiIj0h9d7qjtZBKKSkhKkpaXhgw8+0Gnv1asXkpKSDDQqIiKiJ8/TetyTLALRX3/9hbKyMri4uOi0u7i4ICsrq8rHaLVaaLVa6b5GowEA5Ofn6318RcXamouIiKjB+J/9rNpl+8424PPWoia1yZsNNwAj0hDfr/f3K4R4aJ0sAlEFhUKhc18IUamtQnR0NObOnVup3dPTs0HGRkREVLWVhh7AYzGrgfsvKCiASqWqdrksApGzszNMTU0rbQ3Kzs6utNWoQmRkJKZOnSrdLy8vx61bt+Dk5FRtiKqP/Px8eHp64sqVK7C3t9dbv/RoOC/GifNinDgvxodz8j9CCBQUFMDd3f2hdbIIRBYWFggICEBCQgIGDx4stSckJGDgwIFVPkapVEKpVOq0NWrUqMHGaG9vL/s3rTHivBgnzotx4rwYH87JPQ/bMlRBFoEIAKZOnYrw8HB07NgRQUFB+Ne//oXLly/jnXfeMfTQiIiIyMBkE4iGDBmCmzdvYt68ecjMzESbNm2we/dueHl5GXpoREREZGCyCUQAMGHCBEyYMMHQw9ChVCoxZ86cSrvnyLA4L8aJ82KcOC/Gh3NSdwpR03loRERERE85/to9ERERyR4DEREREckeAxERERHJHgMRERERyR4DkYF98cUX8PHxgaWlJQICAnDkyBFDD+mpdfjwYQwYMADu7u5QKBTYsWOHznIhBKKiouDu7g4rKysEBwfj999/16nRarWYPHkynJ2dYWNjg7CwMFy9evUxrsXTJzo6Gs899xzs7OygVqsxaNAgnD2r++NRnJvHa9WqVWjbtq10Ub+goCD8+OOP0nLOh3GIjo6GQqFARESE1Ma5qT8GIgPatm0bIiIi8OGHH+LXX3/FSy+9hL59++Ly5cuGHtpTqaioCO3atcPKlVX/LtCiRYuwdOlSrFy5EqmpqXB1dUXPnj1RUFAg1URERCAuLg6xsbE4evQoCgsLERoairKysse1Gk+dxMRETJw4ESkpKUhISMDdu3fRq1cvFBUVSTWcm8erSZMmWLBgAY4fP47jx4+je/fuGDhwoPTFyvkwvNTUVPzrX/9C27Ztddo5N49AkME8//zz4p133tFp+9vf/iY++OADA41IPgCIuLg46X55eblwdXUVCxYskNru3LkjVCqVWL16tRBCiLy8PGFubi5iY2OlmmvXrgkTExMRHx//2Mb+tMvOzhYARGJiohCCc2MsHBwcxLp16zgfRqCgoEC0bNlSJCQkiK5du4p3331XCMHPyqPiFiIDKSkpQVpaGnr16qXT3qtXLyQlJRloVPKVkZGBrKwsnflQKpXo2rWrNB9paWkoLS3VqXF3d0ebNm04Z3qk0WgAAI6OjgA4N4ZWVlaG2NhYFBUVISgoiPNhBCZOnIj+/fujR48eOu2cm0cjqytVG5O//voLZWVlcHFx0Wl3cXFBVlaWgUYlXxWveVXzcenSJanGwsICDg4OlWo4Z/ohhMDUqVPx4osvok2bNgA4N4Zy8uRJBAUF4c6dO7C1tUVcXBxat24tfWlyPgwjNjYWv/zyC1JTUyst42fl0TAQGZhCodC5L4So1EaPT33mg3OmP5MmTcKJEydw9OjRSss4N4+Xn58f0tPTkZeXh2+//RYjR45EYmKitJzz8fhduXIF7777Lvbu3QtLS8tq6zg39cNdZgbi7OwMU1PTSok8Ozu7Urqnhufq6goAD50PV1dXlJSUIDc3t9oaqr/Jkyfj+++/x8GDB9GkSROpnXNjGBYWFmjRogU6duyI6OhotGvXDitWrOB8GFBaWhqys7MREBAAMzMzmJmZITExEf/3f/8HMzMz6bXl3NQPA5GBWFhYICAgAAkJCTrtCQkJ6Ny5s4FGJV8+Pj5wdXXVmY+SkhIkJiZK8xEQEABzc3OdmszMTJw6dYpz9giEEJg0aRK2b9+OAwcOwMfHR2c558Y4CCGg1Wo5HwYUEhKCkydPIj09Xbp17NgRI0aMQHp6Opo1a8a5eRSGOZabhBAiNjZWmJubi/Xr14vTp0+LiIgIYWNjIy5evGjooT2VCgoKxK+//ip+/fVXAUAsXbpU/Prrr+LSpUtCCCEWLFggVCqV2L59uzh58qQYNmyYcHNzE/n5+VIf77zzjmjSpInYt2+f+OWXX0T37t1Fu3btxN27dw21Wk+88ePHC5VKJQ4dOiQyMzOl2+3bt6Uazs3jFRkZKQ4fPiwyMjLEiRMnxKxZs4SJiYnYu3evEILzYUzuP8tMCM7No2AgMrDPP/9ceHl5CQsLC9GhQwfpVGPSv4MHDwoAlW4jR44UQtw7ZXXOnDnC1dVVKJVK0aVLF3Hy5EmdPoqLi8WkSZOEo6OjsLKyEqGhoeLy5csGWJunR1VzAkBs2LBBquHcPF5vvfWW9HepcePGIiQkRApDQnA+jMmDgYhzU38KIYQwzLYpIiIiIuPAY4iIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiMjggoODERERYdTPERMTg0aNGultPERkXBiIiIge4O3tjeXLl+u0DRkyBH/++adhBkREDc7M0AMgInoSWFlZwcrKytDDIKIGwi1ERGRUSkpKMGPGDHh4eMDGxgaBgYE4dOiQtPzmzZsYNmwYmjRpAmtra/j7++Prr7/W6aOoqAhvvPEGbG1t4ebmhiVLltT6+YODg3Hp0iW89957UCgUUCgUACrvMouKikL79u3x5ZdfomnTprC1tcX48eNRVlaGRYsWwdXVFWq1Gp9++qlO/xqNBmPHjoVarYa9vT26d++O3377re4vFBHpFQMRERmVN998Ez/99BNiY2Nx4sQJvPbaa+jTpw/OnTsHALhz5w4CAgKwc+dOnDp1CmPHjkV4eDiOHTsm9fH+++/j4MGDiIuLw969e3Ho0CGkpaXV6vm3b9+OJk2aYN68ecjMzERmZma1tRcuXMCPP/6I+Ph4fP311/jyyy/Rv39/XL16FYmJiVi4cCE++ugjpKSkAACEEOjfvz+ysrKwe/dupKWloUOHDggJCcGtW7ce4VUjokdm4B+XJSKSfrH7/PnzQqFQiGvXruksDwkJEZGRkdU+vl+/fmLatGlCCCEKCgqEhYWFiI2NlZbfvHlTWFlZ6fwq+MN4eXmJZcuW6bRt2LBBqFQq6f6cOXOEtbW1yM/Pl9p69+4tvL29RVlZmdTm5+cnoqOjhRBC7N+/X9jb24s7d+7o9N28eXOxZs2aWo2NiBoGjyEiIqPxyy+/QAgBX19fnXatVgsnJycAQFlZGRYsWIBt27bh2rVr0Gq10Gq1sLGxAXBvq01JSQmCgoKkxzs6OsLPz0/v4/X29oadnZ1038XFBaampjAxMdFpy87OBgCkpaWhsLBQWpcKxcXFuHDhgt7HR0S1x0BEREajvLwcpqamSEtLg6mpqc4yW1tbAMCSJUuwbNkyLF++HP7+/rCxsUFERARKSkoA3Nst9biYm5vr3FcoFFW2lZeXA7i3fm5ubjrHRFXgKf1EhsVARERG49lnn0VZWRmys7Px0ksvVVlz5MgRDBw4EH//+98B3AsZ586dQ6tWrQAALVq0gLm5OVJSUtC0aVMAQG5uLv7880907dq1VuOwsLBAWVmZHtZIV4cOHZCVlQUzMzN4e3vrvX8iqj8eVE1ERsPX1xcjRozAG2+8ge3btyMjIwOpqalYuHAhdu/eDeBe4ElISEBSUhLOnDmDcePGISsrS+rD1tYWo0ePxvvvv4/9+/fj1KlTGDVqlM5urJp4e3vj8OHDuHbtGv766y+9rV+PHj0QFBSEQYMGYc+ePbh48SKSkpLw0Ucf4fjx43p7HiKqOwYiIjIqGzZswBtvvIFp06bBz88PYWFhOHbsGDw9PQEAs2fPRocOHdC7d28EBwfD1dUVgwYN0ulj8eLF6NKlC8LCwtCjRw+8+OKLCAgIqPUY5s2bh4sXL6J58+Zo3Lix3tZNoVBg9+7d6NKlC9566y34+vpi6NChuHjxIlxcXPT2PERUdwrxOHe4ExERERkhbiEiIiIi2WMgIiJZOXLkCGxtbau9EZE8cZcZEclKcXExrl27Vu3yFi1aPMbREJGxYCAiIiIi2eMuMyIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSvf8H8yUIWCK0qOkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "booking_kept = train_df.query(\"booking_status == 1\")\n",
    "booking_cancelled = train_df.query(\"booking_status == 0\")\n",
    "plt.hist(x=booking_kept[\"lead_time\"], label=\"kept\", alpha=0.5, bins=20)\n",
    "plt.hist(x=booking_cancelled[\"lead_time\"], label=\"cancelled\", alpha=0.5, bins=20)\n",
    "plt.xlabel(\"lead_time\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(f\"Histogram of booking cancellations by lead time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canceled bookings seem to skew towards the lower end of lead times. This may indicate that this feature is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Bookings Kept and Cancelled'}, xlabel='booking_status', ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.groupby(\"booking_status\").size().plot.bar(title=\"Bookings Kept and Cancelled\", xlabel=\"booking_status\", ylabel=\"Count\", rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bar chart shows that there's a lot more non-canceled bookings than there are cancellations. The imbalance isn't as extreme as previous example, but still, accuracy won't be a good metric alone. Since we want to predict whether a customer will cancel or not, the f1-score would be a good metric since precision and recall are important as well. The project description didn't mention any real-world application of this, so I'm not going to focus too much on recall or precision over the other. (This would be different if I had to consider the cost of FNs or FPs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 4. Feature engineering <a name=\"4\"></a>\n",
    "<hr>\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out feature engineering. In other words, extract new features relevant for the problem and work with your new feature set in the following exercises. You may have to go back and forth between feature engineering and preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28856016, -0.26810729,  1.36868684, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.28856016, -0.26810729,  0.21936289, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.28856016, -0.26810729, -0.92996106, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.28856016, -0.26810729,  0.21936289, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.28856016, -0.26810729, -0.92996106, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.65276003, -0.26810729,  0.21936289, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll identify the different feature types and transformations here. There is no missing data according to the EDA, so I'll skip imputation\n",
    "numeric_features = [\n",
    "    \"no_of_adults\",\n",
    "    \"no_of_children\",\n",
    "    \"no_of_weekend_nights\",\n",
    "    \"no_of_week_nights\",\n",
    "    \"lead_time\",\n",
    "    \"no_of_previous_cancellations\",\n",
    "    \"no_of_previous_bookings_not_canceled\",\n",
    "    \"avg_price_per_room\",\n",
    "    \"no_of_special_requests\",\n",
    "]\n",
    "\n",
    "#I considered ordinal for \n",
    "categorical_features = [\"type_of_meal_plan\", \"room_type_reserved\", \"market_segment_type\", \"arrival_year\", \"arrival_month\", \"arrival_date\"]\n",
    "binary_features = [\"required_car_parking_space\", \"repeated_guest\"]\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "binary_transformer = OneHotEncoder(drop=\"if_binary\", dtype=int)\n",
    "\n",
    "column_transformer = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (binary_transformer, binary_features)\n",
    ")\n",
    "\n",
    "transformed = column_transformer.fit_transform(X_train, y_train)\n",
    "transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline model <a name=\"6\"></a>\n",
    "<hr>\n",
    "\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zweite\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Zweite\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Zweite\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Zweite\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Zweite\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Zweite\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Zweite\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Zweite\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Zweite\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Zweite\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013955</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011999</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011960</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011960</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy  test_f1  train_f1  \\\n",
       "0  0.013955    0.008043       0.673887        0.673887      0.0       0.0   \n",
       "1  0.011998    0.006939       0.673887        0.673887      0.0       0.0   \n",
       "2  0.011999    0.005941       0.673887        0.673887      0.0       0.0   \n",
       "3  0.011960    0.006976       0.673887        0.673887      0.0       0.0   \n",
       "4  0.011960    0.005980       0.673887        0.673887      0.0       0.0   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0          0.0           0.0             0.0              0.0  \n",
       "1          0.0           0.0             0.0              0.0  \n",
       "2          0.0           0.0             0.0              0.0  \n",
       "3          0.0           0.0             0.0              0.0  \n",
       "4          0.0           0.0             0.0              0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = [\n",
    "    \"accuracy\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "]\n",
    "\n",
    "pipeline = make_pipeline(column_transformer, DummyClassifier(strategy=\"prior\"))\n",
    "scores = cross_validate(pipeline, X_train, y_train, return_train_score=True, scoring=scoring)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting some warnings since the DummyClassifier is always predicting 0, so 0 division is happening when precision is being computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Linear models <a name=\"7\"></a>\n",
    "<hr>\n",
    "rubric={points:12}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try logistic regression as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter `C`. \n",
    "3. Report validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093728</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>0.805829</td>\n",
       "      <td>0.810851</td>\n",
       "      <td>0.679662</td>\n",
       "      <td>0.690810</td>\n",
       "      <td>0.631643</td>\n",
       "      <td>0.647947</td>\n",
       "      <td>0.735584</td>\n",
       "      <td>0.739745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083720</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.812918</td>\n",
       "      <td>0.810752</td>\n",
       "      <td>0.693746</td>\n",
       "      <td>0.687683</td>\n",
       "      <td>0.649758</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.744122</td>\n",
       "      <td>0.744546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085713</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.807404</td>\n",
       "      <td>0.813903</td>\n",
       "      <td>0.689524</td>\n",
       "      <td>0.694175</td>\n",
       "      <td>0.655797</td>\n",
       "      <td>0.647645</td>\n",
       "      <td>0.726908</td>\n",
       "      <td>0.747908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083720</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.817251</td>\n",
       "      <td>0.808389</td>\n",
       "      <td>0.693931</td>\n",
       "      <td>0.685926</td>\n",
       "      <td>0.635266</td>\n",
       "      <td>0.641606</td>\n",
       "      <td>0.764535</td>\n",
       "      <td>0.736824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090697</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.800709</td>\n",
       "      <td>0.815282</td>\n",
       "      <td>0.677296</td>\n",
       "      <td>0.696636</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.650362</td>\n",
       "      <td>0.717568</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.093728    0.007931       0.805829        0.810851  0.679662  0.690810   \n",
       "1  0.083720    0.006977       0.812918        0.810752  0.693746  0.687683   \n",
       "2  0.085713    0.006977       0.807404        0.813903  0.689524  0.694175   \n",
       "3  0.083720    0.007973       0.817251        0.808389  0.693931  0.685926   \n",
       "4  0.090697    0.006977       0.800709        0.815282  0.677296  0.696636   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.631643      0.647947        0.735584         0.739745  \n",
       "1     0.649758      0.638889        0.744122         0.744546  \n",
       "2     0.655797      0.647645        0.726908         0.747908  \n",
       "3     0.635266      0.641606        0.764535         0.736824  \n",
       "4     0.641304      0.650362        0.717568         0.750000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=123)\n",
    "pipeline = make_pipeline(column_transformer, lr)\n",
    "\n",
    "scores = cross_validate(pipeline, X_train, y_train, return_train_score=True, scoring=scoring)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy_std</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.809827</td>\n",
       "      <td>0.807168</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.677555</td>\n",
       "      <td>0.621014</td>\n",
       "      <td>0.745893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.811816</td>\n",
       "      <td>0.809295</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.684908</td>\n",
       "      <td>0.635507</td>\n",
       "      <td>0.743036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.812229</td>\n",
       "      <td>0.809689</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.687726</td>\n",
       "      <td>0.642512</td>\n",
       "      <td>0.740105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811835</td>\n",
       "      <td>0.808822</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.686832</td>\n",
       "      <td>0.642754</td>\n",
       "      <td>0.737743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.162278</td>\n",
       "      <td>0.811776</td>\n",
       "      <td>0.808271</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.686289</td>\n",
       "      <td>0.642995</td>\n",
       "      <td>0.736125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.811835</td>\n",
       "      <td>0.808192</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.686283</td>\n",
       "      <td>0.643237</td>\n",
       "      <td>0.735787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.622777</td>\n",
       "      <td>0.811776</td>\n",
       "      <td>0.808350</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.686537</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.736068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.811757</td>\n",
       "      <td>0.808350</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.686537</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.736068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C  train_accuracy  test_accuracy  test_accuracy_std   test_f1  \\\n",
       "0    0.031623        0.809827       0.807168           0.006897  0.677555   \n",
       "1    0.100000        0.811816       0.809295           0.005611  0.684908   \n",
       "2    0.316228        0.812229       0.809689           0.005511  0.687726   \n",
       "3    1.000000        0.811835       0.808822           0.005738  0.686832   \n",
       "4    3.162278        0.811776       0.808271           0.005633  0.686289   \n",
       "5   10.000000        0.811835       0.808192           0.005525  0.686283   \n",
       "6   31.622777        0.811776       0.808350           0.005472  0.686537   \n",
       "7  100.000000        0.811757       0.808350           0.005472  0.686537   \n",
       "\n",
       "   test_recall  test_precision  \n",
       "0     0.621014        0.745893  \n",
       "1     0.635507        0.743036  \n",
       "2     0.642512        0.740105  \n",
       "3     0.642754        0.737743  \n",
       "4     0.642995        0.736125  \n",
       "5     0.643237        0.735787  \n",
       "6     0.643478        0.736068  \n",
       "7     0.643478        0.736068  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_vals = 10.0 ** np.arange(-1.5, 2.5, 0.5)\n",
    "scores = {\n",
    "    \"C\": C_vals, \n",
    "    \"train_accuracy\": [], \n",
    "    \"test_accuracy\": [], \n",
    "    \"test_accuracy_std\": [],\n",
    "    \"test_f1\": [],\n",
    "    \"test_recall\": [],\n",
    "    \"test_precision\": [],\n",
    "}\n",
    "\n",
    "for C in C_vals:\n",
    "    pipeline = make_pipeline(column_transformer, LogisticRegression(max_iter=1000, random_state=123, C=C))    \n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, return_train_score=True, scoring=scoring)\n",
    "\n",
    "    scores[\"train_accuracy\"].append(cv_results[\"train_accuracy\"].mean())\n",
    "    scores[\"test_accuracy\"].append(cv_results[\"test_accuracy\"].mean())\n",
    "    scores[\"test_accuracy_std\"].append(cv_results[\"test_accuracy\"].std())\n",
    "    scores[\"test_f1\"].append(cv_results[\"test_f1\"].mean())\n",
    "    scores[\"test_recall\"].append(cv_results[\"test_recall\"].mean())\n",
    "    scores[\"test_precision\"].append(cv_results[\"test_precision\"].mean())\n",
    "\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067773</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.807798</td>\n",
       "      <td>0.812131</td>\n",
       "      <td>0.681462</td>\n",
       "      <td>0.691262</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.644928</td>\n",
       "      <td>0.741477</td>\n",
       "      <td>0.744770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066777</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.813706</td>\n",
       "      <td>0.811442</td>\n",
       "      <td>0.694247</td>\n",
       "      <td>0.688263</td>\n",
       "      <td>0.648551</td>\n",
       "      <td>0.638285</td>\n",
       "      <td>0.746871</td>\n",
       "      <td>0.746733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.808980</td>\n",
       "      <td>0.813805</td>\n",
       "      <td>0.691279</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.655797</td>\n",
       "      <td>0.644626</td>\n",
       "      <td>0.730821</td>\n",
       "      <td>0.749386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063787</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.817251</td>\n",
       "      <td>0.809078</td>\n",
       "      <td>0.694335</td>\n",
       "      <td>0.686094</td>\n",
       "      <td>0.636473</td>\n",
       "      <td>0.639795</td>\n",
       "      <td>0.763768</td>\n",
       "      <td>0.739616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067772</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.801103</td>\n",
       "      <td>0.814789</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.695286</td>\n",
       "      <td>0.642512</td>\n",
       "      <td>0.647947</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.750087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.067773    0.007974       0.807798        0.812131  0.681462  0.691262   \n",
       "1  0.066777    0.007973       0.813706        0.811442  0.694247  0.688263   \n",
       "2  0.059800    0.007973       0.808980        0.813805  0.691279  0.693069   \n",
       "3  0.063787    0.006977       0.817251        0.809078  0.694335  0.686094   \n",
       "4  0.067772    0.006977       0.801103        0.814789  0.678139  0.695286   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.630435      0.644928        0.741477         0.744770  \n",
       "1     0.648551      0.638285        0.746871         0.746733  \n",
       "2     0.655797      0.644626        0.730821         0.749386  \n",
       "3     0.636473      0.639795        0.763768         0.739616  \n",
       "4     0.642512      0.647947        0.717949         0.750087  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(column_transformer, LogisticRegression(max_iter=1000, random_state=123, C=0.316228))\n",
    "scores = cross_validate(pipeline, X_train, y_train, return_train_score=True, scoring=scoring)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing C doesn't seem to make a huge difference beyond 0.316228 in nearly all metrics apart from recall.\n",
    "Referenced code from HW 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Different classifiers <a name=\"8\"></a>\n",
    "<hr>\n",
    "rubric={points:15}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try at least 3 other models aside from logistic regression. At least one of these models should be a tree-based ensemble model (e.g., lgbm, random forest, xgboost). \n",
    "2. Summarize your results. Can you beat logistic regression? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_summary = {\n",
    "    \"LogisticRegression\": pd.DataFrame(scores).mean()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.634830</td>\n",
       "      <td>0.698632</td>\n",
       "      <td>0.844033</td>\n",
       "      <td>0.871701</td>\n",
       "      <td>0.740838</td>\n",
       "      <td>0.792549</td>\n",
       "      <td>0.683575</td>\n",
       "      <td>0.751510</td>\n",
       "      <td>0.808571</td>\n",
       "      <td>0.838329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.627558</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>0.852304</td>\n",
       "      <td>0.867861</td>\n",
       "      <td>0.758532</td>\n",
       "      <td>0.783129</td>\n",
       "      <td>0.711353</td>\n",
       "      <td>0.731582</td>\n",
       "      <td>0.812414</td>\n",
       "      <td>0.842490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.603638</td>\n",
       "      <td>0.691687</td>\n",
       "      <td>0.846002</td>\n",
       "      <td>0.871800</td>\n",
       "      <td>0.752061</td>\n",
       "      <td>0.791078</td>\n",
       "      <td>0.716184</td>\n",
       "      <td>0.744263</td>\n",
       "      <td>0.791722</td>\n",
       "      <td>0.844178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.653475</td>\n",
       "      <td>0.707639</td>\n",
       "      <td>0.855455</td>\n",
       "      <td>0.869535</td>\n",
       "      <td>0.761533</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>0.707729</td>\n",
       "      <td>0.733696</td>\n",
       "      <td>0.824191</td>\n",
       "      <td>0.845806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.676934</td>\n",
       "      <td>0.707633</td>\n",
       "      <td>0.838913</td>\n",
       "      <td>0.870914</td>\n",
       "      <td>0.737652</td>\n",
       "      <td>0.788923</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.739734</td>\n",
       "      <td>0.786594</td>\n",
       "      <td>0.845119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  1.634830    0.698632       0.844033        0.871701  0.740838  0.792549   \n",
       "1  1.627558    0.697698       0.852304        0.867861  0.758532  0.783129   \n",
       "2  1.603638    0.691687       0.846002        0.871800  0.752061  0.791078   \n",
       "3  1.653475    0.707639       0.855455        0.869535  0.761533  0.785772   \n",
       "4  1.676934    0.707633       0.838913        0.870914  0.737652  0.788923   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.683575      0.751510        0.808571         0.838329  \n",
       "1     0.711353      0.731582        0.812414         0.842490  \n",
       "2     0.716184      0.744263        0.791722         0.844178  \n",
       "3     0.707729      0.733696        0.824191         0.845806  \n",
       "4     0.694444      0.739734        0.786594         0.845119  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(column_transformer, SVC(random_state=123))\n",
    "scores = cross_validate(pipeline, X_train, y_train, return_train_score=True, scoring=scoring)\n",
    "scores_summary[\"SVC\"] = pd.DataFrame(scores).mean()\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.359499</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>0.996652</td>\n",
       "      <td>0.814136</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>0.751208</td>\n",
       "      <td>0.993357</td>\n",
       "      <td>0.888571</td>\n",
       "      <td>0.996366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.313047</td>\n",
       "      <td>0.028903</td>\n",
       "      <td>0.887357</td>\n",
       "      <td>0.996751</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.995017</td>\n",
       "      <td>0.769324</td>\n",
       "      <td>0.994867</td>\n",
       "      <td>0.870219</td>\n",
       "      <td>0.995168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.308670</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>0.878299</td>\n",
       "      <td>0.996948</td>\n",
       "      <td>0.806996</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>0.780193</td>\n",
       "      <td>0.995169</td>\n",
       "      <td>0.835705</td>\n",
       "      <td>0.995470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.306876</td>\n",
       "      <td>0.030893</td>\n",
       "      <td>0.884206</td>\n",
       "      <td>0.996948</td>\n",
       "      <td>0.812977</td>\n",
       "      <td>0.995315</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>0.994263</td>\n",
       "      <td>0.858871</td>\n",
       "      <td>0.996369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309268</td>\n",
       "      <td>0.040033</td>\n",
       "      <td>0.882237</td>\n",
       "      <td>0.997145</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.995612</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.993357</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.997877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  2.359499    0.029900       0.888145        0.996652  0.814136  0.994859   \n",
       "1  0.313047    0.028903       0.887357        0.996751  0.816667  0.995017   \n",
       "2  0.308670    0.034885       0.878299        0.996948  0.806996  0.995319   \n",
       "3  0.306876    0.030893       0.884206        0.996948  0.812977  0.995315   \n",
       "4  0.309268    0.040033       0.882237        0.997145  0.811594  0.995612   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.751208      0.993357        0.888571         0.996366  \n",
       "1     0.769324      0.994867        0.870219         0.995168  \n",
       "2     0.780193      0.995169        0.835705         0.995470  \n",
       "3     0.771739      0.994263        0.858871         0.996369  \n",
       "4     0.777778      0.993357        0.848485         0.997877  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(column_transformer, RandomForestClassifier(random_state=123, n_jobs=-1))\n",
    "scores = cross_validate(pipeline, X_train, y_train, return_train_score=True, scoring=scoring)\n",
    "scores_summary[\"RandomForestClassifier\"] = pd.DataFrame(scores).mean()\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.582315</td>\n",
       "      <td>0.017302</td>\n",
       "      <td>0.876723</td>\n",
       "      <td>0.943186</td>\n",
       "      <td>0.799488</td>\n",
       "      <td>0.910278</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.883756</td>\n",
       "      <td>0.851296</td>\n",
       "      <td>0.938442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.505963</td>\n",
       "      <td>0.015947</td>\n",
       "      <td>0.889720</td>\n",
       "      <td>0.942694</td>\n",
       "      <td>0.824121</td>\n",
       "      <td>0.909711</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>0.885266</td>\n",
       "      <td>0.858639</td>\n",
       "      <td>0.935546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.513938</td>\n",
       "      <td>0.016943</td>\n",
       "      <td>0.876723</td>\n",
       "      <td>0.942891</td>\n",
       "      <td>0.806432</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>0.787440</td>\n",
       "      <td>0.884360</td>\n",
       "      <td>0.826362</td>\n",
       "      <td>0.936980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.494003</td>\n",
       "      <td>0.016945</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>0.943777</td>\n",
       "      <td>0.818878</td>\n",
       "      <td>0.911211</td>\n",
       "      <td>0.775362</td>\n",
       "      <td>0.884662</td>\n",
       "      <td>0.867568</td>\n",
       "      <td>0.939404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.485043</td>\n",
       "      <td>0.016943</td>\n",
       "      <td>0.876329</td>\n",
       "      <td>0.943876</td>\n",
       "      <td>0.805693</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.786232</td>\n",
       "      <td>0.886171</td>\n",
       "      <td>0.826142</td>\n",
       "      <td>0.938299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  1.582315    0.017302       0.876723        0.943186  0.799488  0.910278   \n",
       "1  1.505963    0.015947       0.889720        0.942694  0.824121  0.909711   \n",
       "2  1.513938    0.016943       0.876723        0.942891  0.806432  0.909910   \n",
       "3  1.494003    0.016945       0.888145        0.943777  0.818878  0.911211   \n",
       "4  1.485043    0.016943       0.876329        0.943876  0.805693  0.911491   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.753623      0.883756        0.851296         0.938442  \n",
       "1     0.792271      0.885266        0.858639         0.935546  \n",
       "2     0.787440      0.884360        0.826362         0.936980  \n",
       "3     0.775362      0.884662        0.867568         0.939404  \n",
       "4     0.786232      0.886171        0.826142         0.938299  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(column_transformer, xgb.XGBClassifier(random_state=123, eval_metric=\"logloss\", verbosity=0))\n",
    "scores = cross_validate(pipeline, X_train, y_train, return_train_score=True, scoring=scoring)\n",
    "scores_summary[\"XGBClassifier\"] = pd.DataFrame(scores).mean()\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.065181</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.809768</td>\n",
       "      <td>0.812249</td>\n",
       "      <td>0.687892</td>\n",
       "      <td>0.690795</td>\n",
       "      <td>0.642754</td>\n",
       "      <td>0.643116</td>\n",
       "      <td>0.740177</td>\n",
       "      <td>0.746118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>1.639287</td>\n",
       "      <td>0.700658</td>\n",
       "      <td>0.847341</td>\n",
       "      <td>0.870362</td>\n",
       "      <td>0.750123</td>\n",
       "      <td>0.788290</td>\n",
       "      <td>0.702657</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.804699</td>\n",
       "      <td>0.843184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.719472</td>\n",
       "      <td>0.032923</td>\n",
       "      <td>0.884049</td>\n",
       "      <td>0.996889</td>\n",
       "      <td>0.812474</td>\n",
       "      <td>0.995225</td>\n",
       "      <td>0.770048</td>\n",
       "      <td>0.994203</td>\n",
       "      <td>0.860370</td>\n",
       "      <td>0.996250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>1.516252</td>\n",
       "      <td>0.016816</td>\n",
       "      <td>0.881528</td>\n",
       "      <td>0.943285</td>\n",
       "      <td>0.810922</td>\n",
       "      <td>0.910520</td>\n",
       "      <td>0.778986</td>\n",
       "      <td>0.884843</td>\n",
       "      <td>0.846001</td>\n",
       "      <td>0.937734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fit_time  score_time  test_accuracy  train_accuracy  \\\n",
       "LogisticRegression      0.065181    0.007575       0.809768        0.812249   \n",
       "SVC                     1.639287    0.700658       0.847341        0.870362   \n",
       "RandomForestClassifier  0.719472    0.032923       0.884049        0.996889   \n",
       "XGBClassifier           1.516252    0.016816       0.881528        0.943285   \n",
       "\n",
       "                         test_f1  train_f1  test_recall  train_recall  \\\n",
       "LogisticRegression      0.687892  0.690795     0.642754      0.643116   \n",
       "SVC                     0.750123  0.788290     0.702657      0.740157   \n",
       "RandomForestClassifier  0.812474  0.995225     0.770048      0.994203   \n",
       "XGBClassifier           0.810922  0.910520     0.778986      0.884843   \n",
       "\n",
       "                        test_precision  train_precision  \n",
       "LogisticRegression            0.740177         0.746118  \n",
       "SVC                           0.804699         0.843184  \n",
       "RandomForestClassifier        0.860370         0.996250  \n",
       "XGBClassifier                 0.846001         0.937734  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores_summary).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like RandomForestClassifier beats out the other models in all metrics aside from recall (but it's very, very close with XGBClassifier). LogisticRegression is easily beaten by the others.\n",
    "Referenced lecture 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 9. Feature selection <a name=\"9\"></a>\n",
    "<hr>\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to select relevant features. You may try `RFECV` or forward selection. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it in the next exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "rubric={points:15}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. You may pick one of the best performing models from the previous exercise and tune hyperparameters only for that model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_n_estimators: 700\n",
      "best_max_features:None\n",
      "best_score:0.8165093261552311\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(column_transformer, RandomForestClassifier(random_state=123, n_jobs=-1))\n",
    "\n",
    "n_estimators = [100, 300, 500, 700, 900]\n",
    "max_features = [\"sqrt\", \"log2\", None]\n",
    "\n",
    "param_grid = {\n",
    "    \"randomforestclassifier__n_estimators\": n_estimators,\n",
    "    \"randomforestclassifier__max_features\": max_features,\n",
    "}\n",
    "#commenting out to save time on final run\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring=\"f1\", n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_n_estimators = grid_search.best_params_['randomforestclassifier__n_estimators']\n",
    "best_max_features = grid_search.best_params_['randomforestclassifier__max_features']\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"best_n_estimators: {best_n_estimators}\\nbest_max_features:{best_max_features}\\nbest_score:{best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_n_estimators: 700\n",
    "\n",
    "best_max_features:None \n",
    "\n",
    "best_score:0.8165093261552311 \n",
    "\n",
    "Referenced https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Interpretation and feature importances <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={points:15}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Use the methods we saw in class (e.g., `eli5`, `shap`) (or any other methods of your choice) to explain feature importances of one of the best performing models. Summarize your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "rubric={points:5}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data and report test scores. \n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8283687943262412"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(column_transformer, RandomForestClassifier(random_state=123, n_estimators=700, max_features=None, n_jobs=-1))\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "score = f1_score(y_test, predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 13. Explaining predictions \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks**\n",
    "\n",
    "1. Take one or two test predictions and explain them with SHAP force plots.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary of results <a name=\"13\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Report your final test score along with the metric you used. \n",
    "2. Write concluding remarks.\n",
    "3. Discuss other ideas that you did not try but could potentially improve the performance/interpretability . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran out of time :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from â€œ1â€ will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
